llm:
  chat_endpoints:
    storyteller_default:      
      retries: 1

storyteller:
  narration_preset: "short"
  narration_temperature: 0.35
  memory_top_k: 4
  include_inner_thoughts: false
  refine_enabled: false
  evidence_max_snippets: 2

  # Optional step mode (uncomment to enable)
  step_size: 8
  # step_memory_mode: "per_step_shared"
  # step_retrieval_concurrency: 12
